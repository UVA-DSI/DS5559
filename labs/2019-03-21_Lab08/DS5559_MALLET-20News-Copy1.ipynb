{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "Create an LDA of 20news corpus using MALLET."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = '20news_01.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = '/usr/local/Cellar/mallet/2.0.8/bin/mallet'\n",
    "num_topics = 15\n",
    "num_iters = 1000\n",
    "show_interval = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import re\n",
    "import random\n",
    "import textman as tx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pragmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.read_csv(src_file, sep='\\t')\n",
    "docs = docs.set_index('doc_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Convert corpus to tokens and vocab\n",
    "\n",
    "We use a function from TextMan, a bespoke library that incorporates the text processing routines used in earlier notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, vocab = tx.create_tokens_and_vocab(docs, src_col='doc_content')\n",
    "tokens['token_num'] = tokens.groupby(['doc_id']).cumcount()\n",
    "tokens = tokens.reset_index()[['doc_id','token_num','term_id']]\n",
    "tokens = tokens[tokens.term_id.isin(vocab[vocab.go].index)]\n",
    "tokens = tokens.set_index(['doc_id','token_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add term strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens['term_str'] = tokens.term_id.map(vocab.term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>term_id</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">76209</th>\n",
       "      <th>0</th>\n",
       "      <td>4557</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5848</td>\n",
       "      <td>sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4713</td>\n",
       "      <td>posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2671</td>\n",
       "      <td>forwarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5882</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  term_id   term_str\n",
       "doc_id token_num                    \n",
       "76209  0             4557     people\n",
       "       1             5848       sure\n",
       "       2             4713      posts\n",
       "       3             2671  forwarded\n",
       "       4             5882     system"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Remove insignificant words\n",
    "\n",
    "We use SKlearn's TFIDF vectorizor to quicky get a TFIDF vector space, which we use only to filter the words in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=1, stop_words='english', token_pattern=r'[A-Za-z][A-Za-z][A-Za-z]+')\n",
    "X = vectorizer.fit_transform(docs.doc_content.values.tolist())\n",
    "v = pd.DataFrame(vectorizer.get_feature_names(), columns=['term_str'])\n",
    "v['idf'] = vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaa</td>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>nicely</td>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>nhlpa</td>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>nga</td>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>newswriter</td>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>newsweek</td>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>newspaper</td>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>newsgroups</td>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>newsbytes</td>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3476</th>\n",
       "      <td>newly</td>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str       idf\n",
       "0            aaa  4.921973\n",
       "3491      nicely  4.921973\n",
       "3488       nhlpa  4.921973\n",
       "3486         nga  4.921973\n",
       "3484  newswriter  4.921973\n",
       "3483    newsweek  4.921973\n",
       "3481   newspaper  4.921973\n",
       "3480  newsgroups  4.921973\n",
       "3478   newsbytes  4.921973\n",
       "3476       newly  4.921973"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.sort_values('idf', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take only the most significant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 4.5\n",
    "v = v[v.idf > cutoff].sort_values('idf', ascending=False).sample(1000)\n",
    "my_v = v.term_str.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokens[tokens.term_str.isin(my_v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = vocab[vocab.term.isin(my_v)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export corpus for MALLET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = tx.gather_tokens(tokens, level=0, col='term_str')\\\n",
    "    .reset_index().rename(columns={'term_str':'doc_content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20567</td>\n",
       "      <td>vela afterlife afterlife afterlife vela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20607</td>\n",
       "      <td>easter easter easter easter easter easter asso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20741</td>\n",
       "      <td>saved saved champions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20758</td>\n",
       "      <td>known theology theology visible regards orthod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20859</td>\n",
       "      <td>prayers picture picture picture prayers wounde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                        doc_content\n",
       "0   20567            vela afterlife afterlife afterlife vela\n",
       "1   20607  easter easter easter easter easter easter asso...\n",
       "2   20741                              saved saved champions\n",
       "3   20758  known theology theology visible regards orthod...\n",
       "4   20859  prayers picture picture picture prayers wounde..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_csv('20news-corpus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrecognized command: \n",
      "Mallet 2.0 commands: \n",
      "\n",
      "  import-dir         load the contents of a directory into mallet instances (one per file)\n",
      "  import-file        load a single file into mallet instances (one per line)\n",
      "  import-svmlight    load SVMLight format data files into Mallet instances\n",
      "  info               get information about Mallet instances\n",
      "  train-classifier   train a classifier from Mallet data files\n",
      "  classify-dir       classify data from a single file with a saved classifier\n",
      "  classify-file      classify the contents of a directory with a saved classifier\n",
      "  classify-svmlight  classify data from a single file in SVMLight format\n",
      "  train-topics       train a topic model from Mallet data files\n",
      "  infer-topics       use a trained topic model to infer topics for new documents\n",
      "  evaluate-topics    estimate the probability of new documents under a trained model\n",
      "  prune              remove features based on frequency or information gain\n",
      "  split              divide data into testing, training, and validation portions\n",
      "  bulk-load          for big input files, efficiently prune vocabulary and import docs\n",
      "\n",
      "Include --help with any option for more information\n"
     ]
    }
   ],
   "source": [
    "!{mallet_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{mallet_path} import-file --input 20news-corpus.csv --output 20news-corpus.mallet --keep-sequence TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_config = \"\"\"\n",
    "num-topics = {num_topics} \n",
    "mynum-iterations = {num_iters} \n",
    "myoutput-doc-topics = 20news-doc-topics.txt \n",
    "myoutput-topic-keys = 20news-topic-keys.txt \n",
    "myword-topic-counts-file = 20news-word-topic-counts-file.txt \n",
    "mytopic-word-weights-file = 20news-topic-word-weights-file.txt \n",
    "myxml-topic-report = 20news-topic-report.xml \n",
    "myxml-topic-phrase-report = 20news-topic-phrase-report.xml \n",
    "myshow-topics-interval {show_interval} \n",
    "myuse-symmetric-alpha = false  \n",
    "myoptimize-interval = 100 \n",
    "mydiagnostics-file = 20news-diagnostics.xml\n",
    "\"\"\"\n",
    "mallet_config_file = 'config.txt'\n",
    "with  open(mallet_config_file, 'w') as myfile:\n",
    "    myfile.write(mallet_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to process configuration file: For input string: \"{num_topics}\"\n",
      "Mallet LDA: 10 topics, 4 topic bits, 1111 topic mask\n",
      "Data loaded.\n",
      "max tokens: 72\n",
      "total tokens: 425\n",
      "<10> LL/token: -5.07248\n",
      "<20> LL/token: -4.96296\n",
      "<30> LL/token: -4.85488\n",
      "<40> LL/token: -4.79794\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder suns cnn umd regards alternative kimbark known motss abu centris \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance equal identical ascribed distinctions visible theology salaries \n",
      "2\t0.5\tlie hovig cso bayonets mode champions pouring wpi drivers \n",
      "3\t0.5\tedm det tor hfd phi pit stl saved \n",
      "4\t0.5\tyankees girls printer maddux rickert makhlouf masses abu licence fonts strip iii \n",
      "5\t0.5\tjournalists shot religion throws messiah wounds rotation reno btr unm barry drivers visible \n",
      "6\t0.5\tsabo decisions bryn plenty hade hernlem greig veal harvard \n",
      "7\t0.5\treasoning arguing principles senators record representatives kaldis rule afterlife nextwork belong \n",
      "8\t0.5\teaster khojalu born wounded picture memory sub prayers cdt associate vela \n",
      "9\t0.5\tyalanci society domestic drugs peace smuggling cat books compression courier tel manufacture sub traynor champs \n",
      "\n",
      "<50> LL/token: -4.73019\n",
      "<60> LL/token: -4.75733\n",
      "<70> LL/token: -4.73222\n",
      "<80> LL/token: -4.73455\n",
      "<90> LL/token: -4.76574\n",
      "\n",
      "0\t0.5\tmar juris russotto boulder throws suns cnn umd alternative kimbark rule manufacture unm motss cdt picture \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance equal mode identical ascribed distinctions regards visible greig known theology wpi \n",
      "2\t0.5\thovig cso printer bounced rotation compression reno tel fonts belong iii \n",
      "3\t0.5\tedm det tor hfd phi pit stl \n",
      "4\t0.5\tyankees girls rickert makhlouf abu born masses kaldis licence drivers traynor nextwork strip centris \n",
      "5\t0.5\tjournalists shot religion maddux khojalu messiah wounds champions courier btr afterlife champs saved visible \n",
      "6\t0.5\tsabo decisions bryn plenty cat hade harvard \n",
      "7\t0.5\treasoning arguing principles senators record representatives pouring vela \n",
      "8\t0.5\tsub easter wounded hernlem memory prayers picture barry associate \n",
      "9\t0.5\tyalanci society lie domestic drugs peace smuggling bayonets books veal salaries \n",
      "\n",
      "<100> LL/token: -4.72891\n",
      "<110> LL/token: -4.74412\n",
      "<120> LL/token: -4.73004\n",
      "<130> LL/token: -4.72137\n",
      "<140> LL/token: -4.67406\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder maddux throws suns cnn umd alternative kimbark rule rotation known regards cdt barry \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance visible equal identical ascribed distinctions mode theology belong regards \n",
      "2\t0.5\thovig cso printer abu books bayonets fonts memory iii \n",
      "3\t0.5\tedm det tor hfd phi pit stl unm motss traynor \n",
      "4\t0.5\tyankees girls rickert makhlouf born masses licence drivers manufacture nextwork strip champions \n",
      "5\t0.5\tjournalists shot religion khojalu messiah wounds reno btr champions bayonets champs \n",
      "6\t0.5\tsabo decisions bryn plenty cat hade compression courier harvard salaries centris \n",
      "7\t0.5\treasoning arguing principles senators record representatives veal vela \n",
      "8\t0.5\tsub easter wounded picture kaldis hernlem tel greig pouring prayers afterlife wpi mode associate \n",
      "9\t0.5\tyalanci society lie domestic drugs peace smuggling saved \n",
      "\n",
      "<150> LL/token: -4.66298\n",
      "<160> LL/token: -4.69741\n",
      "<170> LL/token: -4.68885\n",
      "<180> LL/token: -4.72845\n",
      "<190> LL/token: -4.69822\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder suns cnn umd regards alternative kimbark known cdt \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance visible equal identical ascribed distinctions theology traynor saved \n",
      "2\t0.5\thovig cso printer bayonets compression fonts memory unm iii \n",
      "3\t0.5\tedm det tor hfd phi pit stl \n",
      "4\t0.5\tyankees girls rickert makhlouf abu born masses pouring licence drivers nextwork strip \n",
      "5\t0.5\tjournalists shot religion khojalu messiah reno btr wounds belong \n",
      "6\t0.5\tsabo bryn plenty maddux cat hade courier afterlife harvard salaries champs vela \n",
      "7\t0.5\tdecisions reasoning arguing principles senators mode record representatives tel greig veal bayonets \n",
      "8\t0.5\tsub easter throws wounded picture champions kaldis rule rotation hernlem prayers barry wpi centris wounds associate \n",
      "9\t0.5\tyalanci society lie domestic drugs peace smuggling books manufacture motss \n",
      "\n",
      "<200> LL/token: -4.66091\n",
      "<210> LL/token: -4.69149\n",
      "<220> LL/token: -4.70865\n",
      "<230> LL/token: -4.64748\n",
      "<240> LL/token: -4.67414\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder suns umd regards champions alternative kimbark cdt harvard traynor saved picture \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance equal mode identical ascribed distinctions visible known theology \n",
      "2\t0.5\thovig cso bayonets born books manufacture afterlife salaries wpi veal vela \n",
      "3\t0.5\tedm det tor hfd phi pit stl \n",
      "4\t0.5\tyankees girls rickert makhlouf abu masses rotation pouring licence fonts memory motss nextwork strip centris \n",
      "5\t0.5\tjournalists shot religion khojalu messiah wounds reno btr picture belong visible \n",
      "6\t0.5\tsabo bryn plenty printer maddux cat hade compression courier tel barry champs iii \n",
      "7\t0.5\tdecisions reasoning arguing principles senators record representatives kaldis unm veal \n",
      "8\t0.5\tsub easter throws cnn wounded rule hernlem greig drivers prayers associate \n",
      "9\t0.5\tyalanci society lie domestic drugs peace smuggling \n",
      "\n",
      "<250> LL/token: -4.69411\n",
      "<260> LL/token: -4.68611\n",
      "<270> LL/token: -4.68312\n",
      "<280> LL/token: -4.6683\n",
      "<290> LL/token: -4.70078\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder suns cnn umd regards champions alternative kimbark rotation known cdt harvard wpi champs picture \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance visible equal identical ascribed distinctions mode theology saved vela \n",
      "2\t0.5\thovig cso throws bayonets books rule licence associate \n",
      "3\t0.5\tedm det tor hfd phi pit stl \n",
      "4\t0.5\tyankees girls rickert makhlouf abu masses drivers nextwork strip peace \n",
      "5\t0.5\tjournalists shot religion sub khojalu messiah wounds reno btr prayers afterlife belong mode \n",
      "6\t0.5\tsabo bryn plenty printer born cat hade maddux compression courier tel pouring \n",
      "7\t0.5\tdecisions reasoning arguing principles senators record representatives kaldis veal centris \n",
      "8\t0.5\teaster wounded hernlem greig fonts picture unm motss salaries russotto iii \n",
      "9\t0.5\tyalanci society lie domestic drugs smuggling peace manufacture memory maddux barry traynor cso \n",
      "\n",
      "<300> LL/token: -4.73645\n",
      "<310> LL/token: -4.72444\n",
      "<320> LL/token: -4.73523\n",
      "<330> LL/token: -4.6326\n",
      "<340> LL/token: -4.66985\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder suns cnn umd regards alternative kimbark picture known motss cdt \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance visible equal mode identical ascribed distinctions theology wpi \n",
      "2\t0.5\tlie hovig cso throws born books associate \n",
      "3\t0.5\tedm det tor hfd phi pit stl memory \n",
      "4\t0.5\tyankees girls maddux rickert makhlouf abu masses rotation licence drivers unm barry traynor nextwork strip iii vela \n",
      "5\t0.5\tjournalists shot religion khojalu messiah reno btr afterlife belong champs \n",
      "6\t0.5\tsabo bryn printer cat hade compression courier pouring fonts harvard \n",
      "7\t0.5\tdecisions reasoning plenty arguing principles senators record representatives kaldis tel greig salaries veal saved \n",
      "8\t0.5\tsub easter wounded champions rule hernlem prayers centris picture \n",
      "9\t0.5\tyalanci society domestic drugs peace smuggling bayonets wounds manufacture veal \n",
      "\n",
      "<350> LL/token: -4.6517\n",
      "<360> LL/token: -4.63799\n",
      "<370> LL/token: -4.65368\n",
      "<380> LL/token: -4.69607\n",
      "<390> LL/token: -4.69971\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced cnn umd regards alternative kimbark greig suns cdt iii \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance equal mode identical ascribed distinctions tel theology \n",
      "2\t0.5\tlie hovig cso bayonets born books afterlife motss strip suns sub \n",
      "3\t0.5\tedm det tor hfd phi pit stl saved \n",
      "4\t0.5\tyankees girls maddux rickert makhlouf abu masses rotation licence barry salaries \n",
      "5\t0.5\tjournalists shot religion visible khojalu messiah wounds kaldis rule reno btr drivers vela \n",
      "6\t0.5\tsabo bryn printer cat hade champions fonts harvard traynor wpi champs \n",
      "7\t0.5\tdecisions reasoning plenty arguing principles senators record representatives veal manufacture \n",
      "8\t0.5\teaster boulder throws sub wounded picture hernlem compression courier pouring memory prayers known unm nextwork centris \n",
      "9\t0.5\tyalanci society domestic drugs peace smuggling belong associate \n",
      "\n",
      "<400> LL/token: -4.76845\n",
      "<410> LL/token: -4.69579\n",
      "<420> LL/token: -4.65341\n",
      "<430> LL/token: -4.64367\n",
      "<440> LL/token: -4.67694\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder umd picture regards alternative kimbark known unm motss cdt \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance visible equal mode identical ascribed distinctions champions theology saved principles \n",
      "2\t0.5\tlie hovig cso maddux throws greig manufacture memory salaries champs suns \n",
      "3\t0.5\tedm det tor hfd phi pit stl \n",
      "4\t0.5\tyankees girls rickert makhlouf abu masses rotation licence drivers barry nextwork strip wpi iii \n",
      "5\t0.5\tjournalists shot religion khojalu born messiah wounds reno btr belong \n",
      "6\t0.5\tsabo bryn printer cat hade courier fonts harvard traynor centris \n",
      "7\t0.5\tdecisions reasoning plenty arguing senators principles record representatives pouring veal associate \n",
      "8\t0.5\tsub easter cnn books wounded kaldis rule hernlem compression tel suns afterlife vela \n",
      "9\t0.5\tyalanci society domestic drugs peace smuggling bayonets prayers \n",
      "\n",
      "<450> LL/token: -4.71047\n",
      "<460> LL/token: -4.66037\n",
      "<470> LL/token: -4.65942\n",
      "<480> LL/token: -4.68123\n",
      "<490> LL/token: -4.65898\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder cnn umd picture alternative cdt wpi centris prayers \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance visible equal mode identical ascribed distinctions theology \n",
      "2\t0.5\tlie hovig cso peace sub maddux books regards kimbark kaldis tel greig known unm \n",
      "3\t0.5\tedm det tor hfd phi pit stl memory barry nextwork strip champs \n",
      "4\t0.5\tyankees girls rickert throws makhlouf abu masses licence drivers \n",
      "5\t0.5\tjournalists shot religion khojalu born messiah wounds courier reno btr manufacture salaries belong \n",
      "6\t0.5\tsabo bryn plenty printer cat hade compression fonts traynor iii prayers \n",
      "7\t0.5\tdecisions reasoning arguing principles senators record representatives rule veal \n",
      "8\t0.5\teaster suns wounded champions rotation hernlem pouring afterlife motss harvard saved associate vela \n",
      "9\t0.5\tyalanci society domestic drugs smuggling bayonets veal \n",
      "\n",
      "<500> LL/token: -4.72384\n",
      "<510> LL/token: -4.68761\n",
      "<520> LL/token: -4.63182\n",
      "<530> LL/token: -4.71926\n",
      "<540> LL/token: -4.70036\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder throws cnn umd regards alternative kimbark fonts known unm cdt salaries rule \n",
      "1\t0.5\tessence godhead asignation orthodox gregory substance equal identical ascribed distinctions visible mode theology centris \n",
      "2\t0.5\tlie cso sub bayonets picture rule saved peace prayers \n",
      "3\t0.5\tedm det tor hfd phi pit stl \n",
      "4\t0.5\tyankees girls rickert makhlouf abu masses courier licence drivers memory motss harvard traynor nextwork strip associate \n",
      "5\t0.5\tjournalists shot religion khojalu born messiah wounds hernlem reno btr manufacture belong visible \n",
      "6\t0.5\tsabo bryn plenty printer cat hade compression iii mode orthodox \n",
      "7\t0.5\tdecisions reasoning arguing principles senators record representatives rotation \n",
      "8\t0.5\teaster maddux suns wounded champions kaldis tel greig pouring afterlife wpi prayers vela \n",
      "9\t0.5\tyalanci society hovig domestic drugs smuggling peace books veal barry champs \n",
      "\n",
      "<550> LL/token: -4.67368\n",
      "<560> LL/token: -4.67222\n",
      "<570> LL/token: -4.73699\n",
      "<580> LL/token: -4.65004\n",
      "<590> LL/token: -4.66052\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder suns cnn umd wounded regards alternative kimbark centris picture known associate \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance equal mode identical ascribed distinctions visible theology principles known \n",
      "2\t0.5\tyalanci society lie cso peace sub bayonets tel harvard traynor \n",
      "3\t0.5\tedm det tor hfd phi pit stl kaldis \n",
      "4\t0.5\tyankees girls rickert makhlouf abu masses pouring drivers nextwork strip \n",
      "5\t0.5\tjournalists shot religion khojalu born messiah wounds champions reno btr motss salaries belong champs \n",
      "6\t0.5\tsabo bryn plenty cat hade compression courier wpi russotto afterlife \n",
      "7\t0.5\tdecisions reasoning printer arguing senators principles record representatives greig veal fonts memory prayers picture iii visible \n",
      "8\t0.5\teaster maddux throws rule rotation hernlem licence unm cdt barry vela afterlife \n",
      "9\t0.5\thovig domestic drugs smuggling books manufacture saved \n",
      "\n",
      "<600> LL/token: -4.61538\n",
      "<610> LL/token: -4.61792\n",
      "<620> LL/token: -4.64999\n",
      "<630> LL/token: -4.59176\n",
      "<640> LL/token: -4.60063\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder throws suns cnn umd regards champions alternative kimbark kaldis cdt \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance visible equal identical ascribed distinctions known mode theology memory \n",
      "2\t0.5\tyalanci society lie hovig cso peace bayonets picture prayers motss traynor wpi vela \n",
      "3\t0.5\tedm det tor hfd phi pit stl salaries \n",
      "4\t0.5\tyankees girls rickert makhlouf abu masses rule licence drivers nextwork \n",
      "5\t0.5\tjournalists shot religion sub khojalu messiah wounds reno btr tel greig belong \n",
      "6\t0.5\tsabo bryn plenty born cat hade compression courier mode \n",
      "7\t0.5\tdecisions reasoning printer arguing principles senators record representatives afterlife harvard saved \n",
      "8\t0.5\teaster maddux wounded rotation hernlem pouring fonts unm barry strip iii associate \n",
      "9\t0.5\tdomestic drugs smuggling books veal manufacture champs centris memory \n",
      "\n",
      "<650> LL/token: -4.6475\n",
      "<660> LL/token: -4.60978\n",
      "<670> LL/token: -4.63621\n",
      "<680> LL/token: -4.61552\n",
      "<690> LL/token: -4.59138\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder cat cnn umd alternative kimbark suns fonts unm greig \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance visible equal mode identical ascribed distinctions known theology cdt \n",
      "2\t0.5\tyalanci society lie hovig cso peace sub bayonets tel prayers traynor nextwork greig picture \n",
      "3\t0.5\tedm tor det hfd phi pit stl \n",
      "4\t0.5\tyankees girls rickert makhlouf abu masses licence drivers strip \n",
      "5\t0.5\tjournalists shot religion khojalu born messiah wounds champions kaldis reno btr picture belong suns \n",
      "6\t0.5\tsabo bryn plenty hade regards pouring barry harvard salaries det vela \n",
      "7\t0.5\tdecisions reasoning printer arguing principles senators record representatives veal motss champs iii saved \n",
      "8\t0.5\teaster maddux throws wounded rule rotation hernlem compression courier centris \n",
      "9\t0.5\tdomestic drugs smuggling books manufacture memory afterlife wpi associate \n",
      "\n",
      "<700> LL/token: -4.59739\n",
      "<710> LL/token: -4.65047\n",
      "<720> LL/token: -4.6146\n",
      "<730> LL/token: -4.624\n",
      "<740> LL/token: -4.58435\n",
      "\n",
      "0\t0.5\tmar juris russotto printer bounced boulder suns cnn umd regards alternative kimbark memory cdt picture \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance visible equal mode identical ascribed distinctions known theology strip \n",
      "2\t0.5\tyalanci society lie hovig cso peace sub bayonets tel picture books saved \n",
      "3\t0.5\tedm det tor hfd phi pit stl \n",
      "4\t0.5\tyankees girls easter rickert makhlouf abu masses licence drivers nextwork \n",
      "5\t0.5\tjournalists shot religion khojalu born messiah wounds reno btr veal belong \n",
      "6\t0.5\tsabo bryn plenty hade greig books unm traynor champs centris iii \n",
      "7\t0.5\tdecisions reasoning arguing principles senators champions record representatives harvard \n",
      "8\t0.5\tmaddux cat wounded kaldis throws rotation hernlem courier fonts prayers afterlife motss barry associate vela \n",
      "9\t0.5\tdomestic drugs smuggling rule compression pouring manufacture salaries throws wpi \n",
      "\n",
      "<750> LL/token: -4.60042\n",
      "<760> LL/token: -4.64668\n",
      "<770> LL/token: -4.61625\n",
      "<780> LL/token: -4.60823\n",
      "<790> LL/token: -4.62906\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder suns cnn umd picture champions alternative kimbark prayers unm salaries champs iii \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance visible equal mode identical ascribed distinctions regards greig known theology \n",
      "2\t0.5\tyalanci society lie hovig cso peace sub bayonets books \n",
      "3\t0.5\tedm det tor hfd phi pit stl \n",
      "4\t0.5\tyankees girls rickert makhlouf abu masses rotation licence drivers nextwork strip \n",
      "5\t0.5\tjournalists shot religion khojalu born messiah wounds reno btr \n",
      "6\t0.5\tsabo bryn plenty easter hade kaldis associate \n",
      "7\t0.5\tdecisions reasoning arguing principles senators maddux record representatives veal afterlife barry \n",
      "8\t0.5\tprinter throws cat wounded rule hernlem compression courier tel pouring fonts cdt harvard wpi centris saved \n",
      "9\t0.5\tdomestic drugs smuggling manufacture memory motss traynor belong vela \n",
      "\n",
      "<800> LL/token: -4.59372\n",
      "<810> LL/token: -4.63281\n",
      "<820> LL/token: -4.60592\n",
      "<830> LL/token: -4.64225\n",
      "<840> LL/token: -4.56799\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder suns cnn umd alternative kimbark memory regards cdt \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance equal mode identical ascribed distinctions visible known theology afterlife wpi regards \n",
      "2\t0.5\tyalanci society lie hovig cso peace sub iii \n",
      "3\t0.5\tedm det tor hfd phi pit stl \n",
      "4\t0.5\tyankees girls rickert makhlouf abu masses licence drivers nextwork strip domestic saved \n",
      "5\t0.5\tjournalists shot religion khojalu bayonets messiah reno btr greig belong wounds visible associate \n",
      "6\t0.5\tsabo bryn plenty easter throws hade rotation tel harvard pouring vela \n",
      "7\t0.5\tdecisions reasoning arguing principles senators maddux record representatives rule veal \n",
      "8\t0.5\tprinter cat books wounded picture kaldis hernlem compression courier fonts wounds prayers motss barry salaries centris \n",
      "9\t0.5\tdrugs domestic smuggling born champions manufacture unm traynor pouring champs \n",
      "\n",
      "<850> LL/token: -4.58276\n",
      "<860> LL/token: -4.57829\n",
      "<870> LL/token: -4.62042\n",
      "<880> LL/token: -4.65238\n",
      "<890> LL/token: -4.60808\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder suns cnn umd picture regards alternative kimbark known cdt \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance visible equal mode identical ascribed distinctions theology principles \n",
      "2\t0.5\tyalanci society lie hovig cso peace sub bayonets books pouring saved \n",
      "3\t0.5\tedm det tor hfd phi pit stl \n",
      "4\t0.5\tyankees girls maddux rickert makhlouf abu masses rule licence drivers nextwork strip centris \n",
      "5\t0.5\tjournalists shot religion khojalu messiah wounds reno btr tel motss belong wpi champs \n",
      "6\t0.5\tsabo bryn plenty hade kaldis throws hernlem greig harvard \n",
      "7\t0.5\tdecisions reasoning arguing senators wounded principles record representatives rotation veal prayers barry traynor \n",
      "8\t0.5\tprinter easter cat compression fonts memory salaries iii associate \n",
      "9\t0.5\tdomestic drugs smuggling born champions courier manufacture afterlife unm throws vela \n",
      "\n",
      "<900> LL/token: -4.67262\n",
      "<910> LL/token: -4.6342\n",
      "<920> LL/token: -4.63637\n",
      "<930> LL/token: -4.67173\n",
      "<940> LL/token: -4.5934\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder cat umd regards alternative kimbark cdt picture \n",
      "1\t0.5\tessence godhead asignation orthodox gregory substance visible equal mode identical ascribed distinctions known theology unm motss traynor principles \n",
      "2\t0.5\tyalanci society lie hovig cso peace books bayonets pouring \n",
      "3\t0.5\tedm det tor hfd phi pit stl champs associate \n",
      "4\t0.5\tyankees girls rickert makhlouf abu masses licence drivers nextwork strip saved orthodox \n",
      "5\t0.5\tjournalists shot religion sub khojalu messiah wounds reno btr prayers picture bayonets belong \n",
      "6\t0.5\tsabo bryn plenty hade champions greig harvard \n",
      "7\t0.5\tdecisions reasoning arguing senators wounded principles record representatives hernlem memory afterlife salaries veal manufacture \n",
      "8\t0.5\tprinter easter suns cnn courier tel fonts wpi centris russotto iii vela \n",
      "9\t0.5\tdomestic drugs smuggling maddux throws born kaldis rule rotation compression barry veal manufacture \n",
      "\n",
      "<950> LL/token: -4.62416\n",
      "<960> LL/token: -4.61407\n",
      "<970> LL/token: -4.60615\n",
      "<980> LL/token: -4.60638\n",
      "<990> LL/token: -4.62967\n",
      "\n",
      "0\t0.5\tmar juris russotto bounced boulder suns cnn umd champions alternative kimbark regards cdt harvard champs picture \n",
      "1\t0.5\tessence godhead orthodox asignation gregory substance equal identical ascribed distinctions visible known mode theology regards \n",
      "2\t0.5\tyalanci society lie hovig cso peace sub bayonets books tel picture traynor \n",
      "3\t0.5\tedm det tor hfd phi pit stl rule \n",
      "4\t0.5\tyankees girls rickert makhlouf abu masses greig licence drivers unm barry nextwork centris \n",
      "5\t0.5\tjournalists shot religion khojalu messiah wounds kaldis reno btr prayers motss belong visible \n",
      "6\t0.5\tsabo bryn plenty cat hade compression afterlife mode \n",
      "7\t0.5\tdecisions reasoning arguing principles senators record representatives veal memory throws strip saved vela \n",
      "8\t0.5\tprinter easter maddux wounded throws rotation fonts salaries iii \n",
      "9\t0.5\tdomestic drugs smuggling born hernlem courier pouring manufacture wpi associate \n",
      "\n",
      "<1000> LL/token: -4.59828\n",
      "\n",
      "Total time: 0 seconds\n"
     ]
    }
   ],
   "source": [
    "!{mallet_path} train-topics --input 20news-corpus.mallet --config config.txt"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "789px",
    "left": "0px",
    "right": "1186px",
    "top": "111px",
    "width": "254px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
