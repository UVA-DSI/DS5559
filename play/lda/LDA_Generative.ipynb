{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "Demonstrate generative model of LDA using an already inferred model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file = '/Users/rca2t/CODE/polo2-test/PUB/lsi/lsi-mallet-trial1.db'\n",
    "corpus_size = 10\n",
    "doc_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pragras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import tables from db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(db_file) as db:\n",
    "    t = pd.read_sql(\"select topic_id, topic_alpha from topic\", db, index_col='topic_id')\n",
    "    v = pd.read_sql(\"select word_id, word_str from word\", db, index_col='word_id')\n",
    "    dt = pd.read_sql(\"select doc_id, topic_id, topic_weight from doctopic\", db, index_col=['doc_id','topic_id'])\n",
    "    wt = pd.read_sql(\"select word_id, topic_id, word_count from topicword\", db, index_col=['word_id','topic_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DocTopic matrix (THETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = dt.unstack(fill_value=0)\n",
    "DT.columns = DT.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>topic_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.020540</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.257007</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.001889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.010259</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.247030</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.040435</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.079460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.067197</td>\n",
       "      <td>0.050613</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.057509</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.086403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.156332</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.018352</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.128667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.013968</td>\n",
       "      <td>0.014027</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.070064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "topic_id        0         1         2         3         4         5   \\\n",
       "doc_id                                                                 \n",
       "0         0.000495  0.000576  0.020540  0.000389  0.001083  0.000398   \n",
       "1         0.000476  0.010259  0.000331  0.000374  0.001041  0.000382   \n",
       "2         0.000816  0.000951  0.067197  0.050613  0.001786  0.000656   \n",
       "3         0.000415  0.000484  0.000289  0.000326  0.000908  0.000334   \n",
       "4         0.000662  0.000771  0.013968  0.014027  0.001448  0.000532   \n",
       "\n",
       "topic_id        6         7         8         9   ...        30        31  \\\n",
       "doc_id                                            ...                       \n",
       "0         0.000327  0.000163  0.000703  0.000437  ...  0.000381  0.000550   \n",
       "1         0.000314  0.000156  0.000676  0.000420  ...  0.000366  0.000529   \n",
       "2         0.000539  0.000269  0.001160  0.000721  ...  0.000628  0.000908   \n",
       "3         0.000274  0.000137  0.000590  0.000367  ...  0.000320  0.000462   \n",
       "4         0.000437  0.000218  0.000940  0.000585  ...  0.000510  0.000736   \n",
       "\n",
       "topic_id        32        33        34        35        36        37  \\\n",
       "doc_id                                                                 \n",
       "0         0.001205  0.257007  0.001280  0.001678  0.000372  0.000220   \n",
       "1         0.001158  0.247030  0.001231  0.040435  0.000358  0.000211   \n",
       "2         0.001988  0.057509  0.002112  0.002768  0.000614  0.000362   \n",
       "3         0.001011  0.156332  0.001074  0.018352  0.000312  0.000184   \n",
       "4         0.001612  0.087156  0.001713  0.002245  0.000498  0.000294   \n",
       "\n",
       "topic_id        38        39  \n",
       "doc_id                        \n",
       "0         0.000305  0.001889  \n",
       "1         0.009998  0.079460  \n",
       "2         0.000503  0.086403  \n",
       "3         0.000256  0.128667  \n",
       "4         0.000408  0.070064  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create TopicWord Matrix (PHI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT = wt.unstack(fill_value=0)\n",
    "WT.columns = WT.columns.droplevel(0)\n",
    "WT = WT.apply(lambda x: x / x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>topic_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030749</td>\n",
       "      <td>0.023496</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.006257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "topic_id   0    1    2    3    4         5    6         7    8    9   ...  \\\n",
       "word_id                                                               ...   \n",
       "0         0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  ...   \n",
       "1         0.0  0.0  0.0  0.0  0.0  0.001706  0.0  0.000000  0.0  0.0  ...   \n",
       "2         0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  ...   \n",
       "3         0.0  0.0  0.0  0.0  0.0  0.015927  0.0  0.000000  0.0  0.0  ...   \n",
       "4         0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.002339  0.0  0.0  ...   \n",
       "\n",
       "topic_id   30        31        32        33        34        35   36  \\\n",
       "word_id                                                                \n",
       "0         0.0  0.000000  0.030749  0.023496  0.005138  0.000000  0.0   \n",
       "1         0.0  0.000451  0.000000  0.001514  0.000000  0.000273  0.0   \n",
       "2         0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "3         0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "4         0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "\n",
       "topic_id        37        38        39  \n",
       "word_id                                 \n",
       "0         0.001119  0.000000  0.000000  \n",
       "1         0.000000  0.000000  0.000000  \n",
       "2         0.000000  0.000000  0.007110  \n",
       "3         0.000000  0.000679  0.006257  \n",
       "4         0.000000  0.000000  0.004693  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run generative sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .05\n",
    "alpha_array = [alpha for _ in range(len(t.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DOC 0           topic_alpha   n\n",
      "topic_id                 \n",
      "39            0.18712  27\n",
      "13            0.04768  20\n",
      "14            0.33207   7\n",
      "22            0.05966   3\n",
      "necessity qianlong villa currents hideyoshi duty yoshimitsu pioneer commissions painter paralleled ensh garden artist generous muromachi attitude construction preserve toward profound status past architectural replace arrivistes produced would branches mats peculiar palace industrial compositions confusion money ingrained handcut language japan involvement continuity suited sen garden heritage technological new nineteenth yuan practices societies doctrinal footsteps buddhism visualization mus\n",
      "--------------------------------------------------------------------------------\n",
      "DOC 1           topic_alpha   n\n",
      "topic_id                 \n",
      "21            0.07451  21\n",
      "39            0.18712  14\n",
      "5             0.03938   9\n",
      "14            0.33207   8\n",
      "midblock least cherished fervor civil mountain society greekstyle land rebuilding streets outside nondisputatious trips saved new environments anxiety banks invariably topography spaced overpowering even preserve thoreau religious coconspirator capital people laws benefit phillips grid prevailed human crowded area property strategy basins unlike collectively better age strips evil people government public served society\n",
      "--------------------------------------------------------------------------------\n",
      "DOC 2           topic_alpha   n\n",
      "topic_id                 \n",
      "4             0.10721  32\n",
      "32            0.11936  11\n",
      "0             0.04900   3\n",
      "10            0.08109   2\n",
      "9             0.04330   1\n",
      "26            0.11013   1\n",
      "streets constraint jet blows quincunxa spots modernism seem beauxarts style finest artisans art sensations plant paths displayed scottish anticipation spectator sensory idiom round treatise scenery descriptive crafts bend thin ground grecoroman sweep carpet architectural finest landowners never garden topography lszl generation nature gothic treefringed remains made roji profession parnassus tenets\n",
      "--------------------------------------------------------------------------------\n",
      "DOC 3           topic_alpha   n\n",
      "topic_id                 \n",
      "4             0.10721  28\n",
      "32            0.11936  10\n",
      "30            0.03773   6\n",
      "2             0.03412   4\n",
      "26            0.11013   3\n",
      "35            0.16618   2\n",
      "whose opportunity surprise light public themed pitched gentle parnassus informed crafts essay french edges crescenzi art artist painted muchtransformed world artisan darchitecture inventive notion rhydal six conventions declaredbut assistance conditioned categories transcendentalist loo waterheating hypnerotomachia right settings french part scenes vegetation historicizing waterfalls facilities assume casual synergy transition realestate stucco hesitantly apt unrivaled\n",
      "--------------------------------------------------------------------------------\n",
      "DOC 4           topic_alpha   n\n",
      "topic_id                 \n",
      "19            0.06523  15\n",
      "25            0.05729  15\n",
      "31            0.05450   6\n",
      "21            0.07451   4\n",
      "12            0.06684   1\n",
      "chap temples city agora adjacent important glorious walls faubourgs inhabitants greece makes marble feasting considerable centuries tenure smoothpacked kiva dates worshipful parallels people exert protection mexico ward protected building temples life puebloan thomas linking alignment plaza many rituals forces form bce\n",
      "--------------------------------------------------------------------------------\n",
      "DOC 5           topic_alpha   n\n",
      "topic_id                 \n",
      "23            0.03547  16\n",
      "9             0.04330   9\n",
      "31            0.05450   5\n",
      "32            0.11936   4\n",
      "35            0.16618   4\n",
      "26            0.11013   3\n",
      "36            0.03686   3\n",
      "16            0.61584   1\n",
      "20            0.02724   1\n",
      "33            0.45253   1\n",
      "interested landscape vau type enraging program onequarter royal petite frondeurs ambitious grand cooking vestigial hornblowing walls towers movements interlacing curriculum superabundance client italy average barchesse changed jussieu walls commanded exotic jules successors plant shrubs samarkand landscaped kew europe shared progression like king therefore viceroy vauxlevicomte pertaining seat\n",
      "--------------------------------------------------------------------------------\n",
      "DOC 6           topic_alpha   n\n",
      "topic_id                 \n",
      "2             0.03412  26\n",
      "3             0.03850  14\n",
      "36            0.03686   7\n",
      "7             0.01612   5\n",
      "11            0.16713   2\n",
      "33            0.45253   2\n",
      "4             0.10721   1\n",
      "war lived signs good existence league lynch reasons conceptualizing shopping pavilion increasing overlook fha planes longer fountain islamic dumbbell center much jungian recreate rationalism technologically affect anyone quintessential teamwould pottery girling disneyland service sightseeing individually settling giving designers techniques cinematic countered tourist exclusion safavid space chabutra airless producing receptacles ordered summer delectation sets directional cathartic infrastructures trylon\n",
      "--------------------------------------------------------------------------------\n",
      "DOC 7           topic_alpha   n\n",
      "topic_id                 \n",
      "7             0.01612  16\n",
      "28            0.09044  15\n",
      "20            0.02724  10\n",
      "11            0.16713   3\n",
      "3             0.03850   1\n",
      "25            0.05729   1\n",
      "29            0.26671   1\n",
      "39            0.18712   1\n",
      "natural florida realm charming farrand repairs colonialrevival red forth veterans lawn symbolized trustworthy miniaturized uncentered rallying mount cultural signed costume resort newly leading palm bursting appliances brains millers tragedy farrand long trees acquaintance purpose woodland schedules appliances california prowess messageladen earth opting horticulture thefts memorial including pain wild\n",
      "--------------------------------------------------------------------------------\n",
      "DOC 8           topic_alpha  n\n",
      "topic_id                \n",
      "15            0.02510  9\n",
      "16            0.61584  8\n",
      "29            0.26671  7\n",
      "18            0.07680  6\n",
      "32            0.11936  6\n",
      "11            0.16713  2\n",
      "24            0.06563  2\n",
      "4             0.10721  1\n",
      "7             0.01612  1\n",
      "8             0.06962  1\n",
      "14            0.33207  1\n",
      "36            0.03686  1\n",
      "tower pebbles safer love christian mehmed fair canal hill courses could flourished upon literary halprin giant ranch equally atop flanking almost elizabeth retaining diet superseded gatepost set significant nature destroyed inspired state lost revive words era irrigation sixteenth golfing hundred columbus jensen regional earth industrial\n",
      "--------------------------------------------------------------------------------\n",
      "DOC 9           topic_alpha   n\n",
      "topic_id                 \n",
      "8             0.06962  29\n",
      "9             0.04330   6\n",
      "30            0.03773   4\n",
      "32            0.11936   3\n",
      "33            0.45253   1\n",
      "38            0.03018   1\n",
      "architect niches jardinage consisting parc california work printer plants olmsted intimations bill study california grounds technology parkway revisit outlining boyhood whole board acquaint plantings dozen america valuesdesigners spurned rochester tugwell first bill county appropriating physiography yosemite aside parkside clarke operations geometric felicity olmsted founded\n"
     ]
    }
   ],
   "source": [
    "for d in range(corpus_size):\n",
    "    \n",
    "    doc_text = []\n",
    "    doc_topics = t.copy()\n",
    "    doc_topics['n'] = 0\n",
    "    \n",
    "    # Pick the size  of the document\n",
    "    N = np.random.poisson(doc_size)\n",
    "    \n",
    "    # Pick a Dirichlet distribution of topics\n",
    "    theta = np.random.dirichlet(alpha_array)\n",
    "    \n",
    "    # Or: pick an existing distribution\n",
    "#     theta = DT.sample().iloc[0]\n",
    "    \n",
    "    for _ in range(N):\n",
    "        z = t.sample(weights=theta).index[0]\n",
    "        phi = WT[z].values\n",
    "        w = v.sample(weights=phi).index[0]\n",
    "        w_str = v.loc[w].word_str\n",
    "        doc_text.append(w_str)\n",
    "        doc_topics.loc[z, 'n'] += 1\n",
    "    \n",
    "    print('-' * 80)\n",
    "    print(\"DOC\", d, doc_topics[doc_topics.n > 0].sort_values('n',  ascending=False))\n",
    "    print(' '.join(doc_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate using SQL\n",
    "\n",
    "The join operator in SQL is like a multiplication operator in probability.\n",
    "\n",
    "$p(w|\\theta, \\phi) = \\sum_{z}p(w|z,\\phi)p(z|\\theta)$\n",
    "\n",
    "$p(w|z,\\phi)p(z|\\theta) \\equiv$\n",
    "\n",
    "$p(w|t)p(t|w) \\equiv$\n",
    "\n",
    "```\n",
    "SELECT dt.weight * tw.weight \n",
    "FROM wt JOIN td USING(topic_id) \n",
    "WHERE doc_id = ?\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```\n",
    "SELECT dt.weight * tw.weight \n",
    "FROM wt, td \n",
    "WHERE wt.topic_id = tw.topic_id AND doc_id = ?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select word_id, word_str, sum(p_wz)as p_w\n",
    "from (\n",
    "    select topic_id, word_id, round((topic_weight * word_p), 8) as p_wz\n",
    "    from doctopic theta join topicword_v phi using(topic_id)\n",
    "    where theta.doc_id = ?\n",
    ")\n",
    "join word using(word_id)\n",
    "group by word_id\n",
    "order by p_W  desc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_doc_id = 100\n",
    "with sqlite3.connect(db_file) as db:\n",
    "    p_wGd = pd.read_sql(sql, db, index_col='word_id', params=(my_doc_id,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_str</th>\n",
       "      <th>p_w</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20698</th>\n",
       "      <td>churchmen</td>\n",
       "      <td>3.100000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>necessarily</td>\n",
       "      <td>6.339900e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14480</th>\n",
       "      <td>eleonora</td>\n",
       "      <td>1.800000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>nostalgic</td>\n",
       "      <td>8.703000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>interesting</td>\n",
       "      <td>1.028100e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19796</th>\n",
       "      <td>secretary</td>\n",
       "      <td>1.310000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>anshen</td>\n",
       "      <td>8.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11494</th>\n",
       "      <td>southeastnorthwest</td>\n",
       "      <td>2.800000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>centrifugal</td>\n",
       "      <td>3.840300e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>disseminated</td>\n",
       "      <td>1.729000e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   word_str           p_w\n",
       "word_id                                  \n",
       "20698             churchmen  3.100000e-07\n",
       "1               necessarily  6.339900e-04\n",
       "14480              eleonora  1.800000e-07\n",
       "3114              nostalgic  8.703000e-05\n",
       "5388            interesting  1.028100e-04\n",
       "19796             secretary  1.310000e-06\n",
       "2162                 anshen  8.000000e-08\n",
       "11494    southeastnorthwest  2.800000e-07\n",
       "524             centrifugal  3.840300e-04\n",
       "3892           disseminated  1.729000e-05"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_wGd.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOC 0\n",
      "usuallylocated became type culture integrated time generated thus measurement viewing capitalist uses public states japan also also specific view become suburbs along industrial mile urban throughout owner second focused strong seventeenth role lake design districts highway become three time planning grew metropolitan first need neighborhoods routes technology lowcost native true artists \n",
      "--------------------------------------------------------------------------------\n",
      "DOC 1\n",
      "new heaven founder place incity cities inlet another views old wide creating used lead photography southern messages inscriptions mountains becoming posits grade augusta riddles public new especially new one resulting view established design landscape cityin theory edge accurately natural growth edge rationality oncehandsome avenue market suburbs sockets like words new wealthiest \n",
      "--------------------------------------------------------------------------------\n",
      "DOC 2\n",
      "landscapes association institutions kind railroads new class concepts looked miles appeal five become forever philosophy town made facilitate among characterize notion distinction create dreams along enjoyed accomplished living enlarged extension class fresh role came role shape cities centers north effortless outlined welltodo viewing recreational written conurbations diversity recreational airports built \n",
      "--------------------------------------------------------------------------------\n",
      "DOC 3\n",
      "resembling another others region jung fanned cold serve architects function follow become lingers nothing people top paralleled totemic west running left social attended viewer utility building local various lake forms period murray universe scale long viewed distance much philosophy routes vested desirable set attended high activities hospitably beginning repeating landscape beautiful express gate demonstrates semicircular sense toppled may perception second \n",
      "--------------------------------------------------------------------------------\n",
      "DOC 4\n",
      "also freedom figs fitness needs point depicts visitation state ionia per phenomenon developers autonomous ends wall unstructured great exist study linking expression relationship thoroughly dollars new particularly largest lines cultural cities one life \n",
      "--------------------------------------------------------------------------------\n",
      "DOC 5\n",
      "though place prosperous garden succeed terms possible contemporary place life intelligent highart emanating century rectangular voyage mansard political rule open home platform regulations become city incentive center heritage highrise pantheon type powerful would galileo create pyramid come certain pleasurable schafer leading understanding length passion larger new historical within separated infrastructure highly market greenbelts integrated conspicuous island others realize \n",
      "--------------------------------------------------------------------------------\n",
      "DOC 6\n",
      "federal whose could automobile thus wild widely edge historians increased broadcast thanks siting history intimately meaning elaborated architectural influence appropriate found reality well memory advertising residential cities roots sixteenth though rather distance local perspectives desire relativity roman often military palpable planted remained yet champion proposed members become grown appears continued sparkling northeast time leading \n",
      "--------------------------------------------------------------------------------\n",
      "DOC 7\n",
      "hand everyday need workaday merleauponty written busts improvements seen involved satellite thereby persia called industrial suburbs architectural transportation directly fertile idioms agencies another smooth many state industrialage wilderness urban second raised one planned employed progressive rebuilding one placed declared fitness ends stationary attention local true sweeping war nature first cosmos slopes housing corporations fabric landscape brought transforming province people \n",
      "--------------------------------------------------------------------------------\n",
      "DOC 8\n",
      "outdoor eastern states importance throughout disciplines network weaves made uplifting although artificiality meters last stems kind zone model place gained spheres divergent immutable public casual feet domestic parks wealth natural cars network park feature transportation beyond new three brilliant livable nature bridge romanticizing workplace follow york manner monument leading city function understated place round \n",
      "--------------------------------------------------------------------------------\n",
      "DOC 9\n",
      "builders larger order transformed commuter one place technology makes home better corbusier recreational thorough given places eyes poetics river canaltriclinium one industrial houses work planning lines observation much amiable ntre become artists term possible courses axis setting life along still street horizontality design urban undertaken religious became beautiful martial resulting yet high design pilgrimage psychology provided trackless time city urban centers nature place american cascade \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(corpus_size):\n",
    "    print('DOC',  i)\n",
    "    N = np.random.poisson(50)\n",
    "    for j in range(N):\n",
    "        w = v.sample(weights=p_wGd.p_w)\n",
    "        print(w.word_str.values[0], end=' ')\n",
    "    print()\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
